{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Binary classification using Tensor flow",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1YOOh_iBzMLsQ76CTsIR5M7Ow03_K25vs",
          "timestamp": 1522780024486
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "xVjLbw0HP8S1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "waEIIxj_VE-2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generate tain and test data"
      ]
    },
    {
      "metadata": {
        "id": "mFV4qJCvVEK6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X, Y = make_classification(n_samples=50000, n_features=10, n_informative=8, \n",
        "                           n_redundant=0, n_clusters_per_class=2)\n",
        "Y = np.array([Y, -(Y-1)]).T  # The model currently needs one column for each class\n",
        "X, X_test, Y, Y_test = train_test_split(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIL_LHvPVRKk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Parameters"
      ]
    },
    {
      "metadata": {
        "id": "Z7VhCiCbVTvE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 100\n",
        "batch_size = 100\n",
        "display_step = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NN517b71VYk7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Network Parameters"
      ]
    },
    {
      "metadata": {
        "id": "ax1_yJ_yVV_c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_hidden_1 = 10 # 1st layer number of features\n",
        "n_hidden_2 = 10 # 2nd layer number of features\n",
        "n_input = 10 # Number of feature\n",
        "n_classes = 2 # Number of classes to predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zDDUrPgVdE0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf Graph input"
      ]
    },
    {
      "metadata": {
        "id": "pUe_RDSaVg3o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(\"float\", [None, n_input])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "engCRs5lVmhn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create model"
      ]
    },
    {
      "metadata": {
        "id": "gEJpZrbeVkYN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def multilayer_perceptron(x, weights, biases):\n",
        "    # Hidden layer with RELU activation\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    # Hidden layer with RELU activation\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    # Output layer with linear activation\n",
        "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
        "    return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O7-kDAxlVrOv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Store layers weight & bias"
      ]
    },
    {
      "metadata": {
        "id": "bJhyns3GVt2I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "weights = {\n",
        "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7Ou4skBVxvK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construct model"
      ]
    },
    {
      "metadata": {
        "id": "qenHZqkCV0Ax",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pred = multilayer_perceptron(x, weights, biases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCsBtQldV5wC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define loss and optimizer"
      ]
    },
    {
      "metadata": {
        "id": "grpzEjSWV4ud",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "daee14d6-c636-4fd1-8a88-32af6c87af50",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522722656895,
          "user_tz": -330,
          "elapsed": 1149,
          "user": {
            "displayName": "Vaishnavi Rao",
            "photoUrl": "//lh4.googleusercontent.com/-5cvswkoqrIw/AAAAAAAAAAI/AAAAAAAAA2w/Ufah_Ry1fTY/s50-c-k-no/photo.jpg",
            "userId": "114549807758590246828"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-167cf8c6f393>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pFrwwLtOV_Bk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Initializing the variables"
      ]
    },
    {
      "metadata": {
        "id": "5y6hPP9wWB46",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ueT4Thp2WGQ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Launch the graph"
      ]
    },
    {
      "metadata": {
        "id": "HeMHjoZGWJcT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "b60ded42-d916-4f7e-8bb6-af8528e1e77d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522722750221,
          "user_tz": -330,
          "elapsed": 26015,
          "user": {
            "displayName": "Vaishnavi Rao",
            "photoUrl": "//lh4.googleusercontent.com/-5cvswkoqrIw/AAAAAAAAAAI/AAAAAAAAA2w/Ufah_Ry1fTY/s50-c-k-no/photo.jpg",
            "userId": "114549807758590246828"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    # Training cycle\n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0.\n",
        "        total_batch = int(len(X)/batch_size)\n",
        "        X_batches = np.array_split(X, total_batch)\n",
        "        Y_batches = np.array_split(Y, total_batch)\n",
        "        # Loop over all batches\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = X_batches[i], Y_batches[i]\n",
        "            # Run optimization op (backprop) and cost op (to get loss value)\n",
        "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
        "                                                          y: batch_y})\n",
        "            # Compute average loss\n",
        "            avg_cost += c / total_batch\n",
        "        # Display logs per epoch step\n",
        "        if epoch % display_step == 0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    # Test model\n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    print(\"Accuracy:\", accuracy.eval({x: X_test, y: Y_test}))\n",
        "    global result \n",
        "    result = tf.argmax(pred, 1).eval({x: X_test, y: Y_test})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Epoch:', '0001', 'cost=', '3.424794162')\n",
            "('Epoch:', '0002', 'cost=', '0.699254882')\n",
            "('Epoch:', '0003', 'cost=', '0.467894121')\n",
            "('Epoch:', '0004', 'cost=', '0.381611425')\n",
            "('Epoch:', '0005', 'cost=', '0.322576102')\n",
            "('Epoch:', '0006', 'cost=', '0.281613927')\n",
            "('Epoch:', '0007', 'cost=', '0.253879480')\n",
            "('Epoch:', '0008', 'cost=', '0.233681110')\n",
            "('Epoch:', '0009', 'cost=', '0.218087465')\n",
            "('Epoch:', '0010', 'cost=', '0.206053527')\n",
            "('Epoch:', '0011', 'cost=', '0.197085907')\n",
            "('Epoch:', '0012', 'cost=', '0.190008190')\n",
            "('Epoch:', '0013', 'cost=', '0.184188794')\n",
            "('Epoch:', '0014', 'cost=', '0.179103605')\n",
            "('Epoch:', '0015', 'cost=', '0.174624914')\n",
            "('Epoch:', '0016', 'cost=', '0.170451854')\n",
            "('Epoch:', '0017', 'cost=', '0.166625590')\n",
            "('Epoch:', '0018', 'cost=', '0.163412480')\n",
            "('Epoch:', '0019', 'cost=', '0.160384700')\n",
            "('Epoch:', '0020', 'cost=', '0.157434107')\n",
            "('Epoch:', '0021', 'cost=', '0.154585581')\n",
            "('Epoch:', '0022', 'cost=', '0.152051954')\n",
            "('Epoch:', '0023', 'cost=', '0.149649706')\n",
            "('Epoch:', '0024', 'cost=', '0.147492675')\n",
            "('Epoch:', '0025', 'cost=', '0.145765804')\n",
            "('Epoch:', '0026', 'cost=', '0.144288879')\n",
            "('Epoch:', '0027', 'cost=', '0.142789408')\n",
            "('Epoch:', '0028', 'cost=', '0.141333615')\n",
            "('Epoch:', '0029', 'cost=', '0.139849677')\n",
            "('Epoch:', '0030', 'cost=', '0.138432423')\n",
            "('Epoch:', '0031', 'cost=', '0.137167333')\n",
            "('Epoch:', '0032', 'cost=', '0.135796793')\n",
            "('Epoch:', '0033', 'cost=', '0.134555107')\n",
            "('Epoch:', '0034', 'cost=', '0.133556705')\n",
            "('Epoch:', '0035', 'cost=', '0.132663064')\n",
            "('Epoch:', '0036', 'cost=', '0.131830755')\n",
            "('Epoch:', '0037', 'cost=', '0.131039017')\n",
            "('Epoch:', '0038', 'cost=', '0.130330994')\n",
            "('Epoch:', '0039', 'cost=', '0.129656444')\n",
            "('Epoch:', '0040', 'cost=', '0.128970564')\n",
            "('Epoch:', '0041', 'cost=', '0.128266850')\n",
            "('Epoch:', '0042', 'cost=', '0.127523583')\n",
            "('Epoch:', '0043', 'cost=', '0.126786418')\n",
            "('Epoch:', '0044', 'cost=', '0.126068166')\n",
            "('Epoch:', '0045', 'cost=', '0.125290830')\n",
            "('Epoch:', '0046', 'cost=', '0.124379620')\n",
            "('Epoch:', '0047', 'cost=', '0.123413513')\n",
            "('Epoch:', '0048', 'cost=', '0.122457896')\n",
            "('Epoch:', '0049', 'cost=', '0.121413204')\n",
            "('Epoch:', '0050', 'cost=', '0.120308043')\n",
            "('Epoch:', '0051', 'cost=', '0.119347517')\n",
            "('Epoch:', '0052', 'cost=', '0.118405044')\n",
            "('Epoch:', '0053', 'cost=', '0.117461879')\n",
            "('Epoch:', '0054', 'cost=', '0.116574658')\n",
            "('Epoch:', '0055', 'cost=', '0.115839668')\n",
            "('Epoch:', '0056', 'cost=', '0.115031523')\n",
            "('Epoch:', '0057', 'cost=', '0.114211853')\n",
            "('Epoch:', '0058', 'cost=', '0.113486661')\n",
            "('Epoch:', '0059', 'cost=', '0.112735864')\n",
            "('Epoch:', '0060', 'cost=', '0.111982563')\n",
            "('Epoch:', '0061', 'cost=', '0.111279384')\n",
            "('Epoch:', '0062', 'cost=', '0.110607803')\n",
            "('Epoch:', '0063', 'cost=', '0.109982158')\n",
            "('Epoch:', '0064', 'cost=', '0.109441402')\n",
            "('Epoch:', '0065', 'cost=', '0.108910328')\n",
            "('Epoch:', '0066', 'cost=', '0.108421839')\n",
            "('Epoch:', '0067', 'cost=', '0.107940200')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "('Epoch:', '0068', 'cost=', '0.107471950')\n",
            "('Epoch:', '0069', 'cost=', '0.107030362')\n",
            "('Epoch:', '0070', 'cost=', '0.106578360')\n",
            "('Epoch:', '0071', 'cost=', '0.106160172')\n",
            "('Epoch:', '0072', 'cost=', '0.105711427')\n",
            "('Epoch:', '0073', 'cost=', '0.105213039')\n",
            "('Epoch:', '0074', 'cost=', '0.104740817')\n",
            "('Epoch:', '0075', 'cost=', '0.104267586')\n",
            "('Epoch:', '0076', 'cost=', '0.103838294')\n",
            "('Epoch:', '0077', 'cost=', '0.103438342')\n",
            "('Epoch:', '0078', 'cost=', '0.103050668')\n",
            "('Epoch:', '0079', 'cost=', '0.102714108')\n",
            "('Epoch:', '0080', 'cost=', '0.102366315')\n",
            "('Epoch:', '0081', 'cost=', '0.102053392')\n",
            "('Epoch:', '0082', 'cost=', '0.101773830')\n",
            "('Epoch:', '0083', 'cost=', '0.101485557')\n",
            "('Epoch:', '0084', 'cost=', '0.101199054')\n",
            "('Epoch:', '0085', 'cost=', '0.100920662')\n",
            "('Epoch:', '0086', 'cost=', '0.100665854')\n",
            "('Epoch:', '0087', 'cost=', '0.100413267')\n",
            "('Epoch:', '0088', 'cost=', '0.100155917')\n",
            "('Epoch:', '0089', 'cost=', '0.099876538')\n",
            "('Epoch:', '0090', 'cost=', '0.099583482')\n",
            "('Epoch:', '0091', 'cost=', '0.099308982')\n",
            "('Epoch:', '0092', 'cost=', '0.099021802')\n",
            "('Epoch:', '0093', 'cost=', '0.098717299')\n",
            "('Epoch:', '0094', 'cost=', '0.098459436')\n",
            "('Epoch:', '0095', 'cost=', '0.098166276')\n",
            "('Epoch:', '0096', 'cost=', '0.097838018')\n",
            "('Epoch:', '0097', 'cost=', '0.097455070')\n",
            "('Epoch:', '0098', 'cost=', '0.097040517')\n",
            "('Epoch:', '0099', 'cost=', '0.096649164')\n",
            "('Epoch:', '0100', 'cost=', '0.096144325')\n",
            "Optimization Finished!\n",
            "('Accuracy:', 0.96944)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}