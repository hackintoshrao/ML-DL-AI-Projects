{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_keras_functional_multinomial.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1tdUPLgbNVMvO5SPcc4XAfqHzOLhSoXb4",
          "timestamp": 1524466254418
        },
        {
          "file_id": "1NV77r4wgqT7YBIj6ngj0vXOXguZnJSTl",
          "timestamp": 1524360411042
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "eGGFM3vp7AGs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Sentiment Analysis:** the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral. \n"
      ]
    },
    {
      "metadata": {
        "id": "NKwryeAn7AGy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "xyWrujbd7AG0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense ,LSTM,concatenate,Input,Flatten\n",
        "import re\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeDIRX6Q7AHC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Only keeping the necessary columns."
      ]
    },
    {
      "metadata": {
        "id": "5jzvy4R57AHG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a6f4608-42f3-4b3b-948c-79cafbb76e88",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524469934656,
          "user_tz": -330,
          "elapsed": 1312,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://play.minio.io:9000/rao/data_1_train.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=Q3AM3UQ867SPQQA43P2F%2F20180422%2F%2Fs3%2Faws4_request&X-Amz-Date=20180422T014411Z&X-Amz-Expires=432000&X-Amz-SignedHeaders=host&X-Amz-Signature=30f103b98d02bf9a8271aa3347d2872d313cfb882a068a1f205ea0e6d1f50a69')\n",
        "# Keeping only the neccessary columns\n",
        "print (data.columns.tolist())\n",
        "\n",
        "data = data[[' text',' class']]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['example_id', ' text', ' aspect_term', ' term_location', ' class']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H97KzpuR7AHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "NWw_2yXA7AHU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "989090cd-59e9-4862-dcf6-9f10b9861af7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524469936286,
          "user_tz": -330,
          "elapsed": 1400,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#data = data[data.sentiment != \"Neutral\"]\n",
        "data[' text'] = data[' text'].apply(lambda x: x.lower())\n",
        "data[' text'] = data[' text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "print(data[ data[' class'] == 1].size)\n",
        "print(data[ data[' class'] == 0].size)\n",
        "print(data[ data[' class'] == -1].size)\n",
        "\n",
        "\n",
        "max_fatures = 1000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data[' text'].values)\n",
        "X = tokenizer.texts_to_sequences(data[' text'].values)\n",
        "X = pad_sequences(X)\n",
        "print(X.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1878\n",
            "872\n",
            "1656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GekL5Y7g7AHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, I compose the LSTM Network. Note that **embed_dim**, **lstm_out**, **batch_size**, **droupout_x** variables are hyperparameters, their values are somehow intuitive, can be and must be played with in order to achieve good results. Please also note that I am using softmax as activation function. The reason is that our Network is using categorical crossentropy, and softmax is just the right activation method for that."
      ]
    },
    {
      "metadata": {
        "id": "kmiIF-oF7AHi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "4077b9aa-4604-489a-a8de-97c173ccde5b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524470055244,
          "user_tz": -330,
          "elapsed": 2210,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "\n",
        "input_1 = Input(shape=(1785, ))\n",
        "word_embedding = Embedding(max_fatures, embed_dim,input_length = X.shape[1])(input_1)\n",
        "drop_out_1 = SpatialDropout1D(0.4)(word_embedding)\n",
        "lstm_1 = LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)(drop_out_1)\n",
        "\n",
        "output = Dense(3,activation='softmax')(lstm_1)\n",
        "\n",
        "model = Model(inputs=[input_1], outputs=output)\n",
        "\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "    \n",
        "print(model.summary())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 1785)              0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 1785, 128)         128000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_4 (Spatial (None, 1785, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 591       \n",
            "=================================================================\n",
            "Total params: 383,391\n",
            "Trainable params: 383,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4U3gK3rP7AHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hereby I declare the train and test dataset."
      ]
    },
    {
      "metadata": {
        "id": "1FTHSrn97AHq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d558c17a-ec3c-43e7-8473-1910a1c0f0ee",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524470056566,
          "user_tz": -330,
          "elapsed": 1012,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(data[' class']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((1476, 1785), (1476, 3))\n",
            "((727, 1785), (727, 3))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LJewLDTr7AHy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "ebe19bb0-bed8-4f30-82ad-bbadcc44d7d7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524477233468,
          "user_tz": -330,
          "elapsed": 7176638,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            " - 1605s - loss: 1.0307 - acc: 0.4898\n",
            "Epoch 2/7\n",
            " - 1171s - loss: 0.8084 - acc: 0.6477\n",
            "Epoch 3/7\n",
            " - 1246s - loss: 0.6186 - acc: 0.7473\n",
            "Epoch 4/7\n",
            " - 788s - loss: 0.5187 - acc: 0.8089\n",
            "Epoch 5/7\n",
            " - 785s - loss: 0.4769 - acc: 0.8184\n",
            "Epoch 6/7\n",
            " - 790s - loss: 0.4049 - acc: 0.8462\n",
            "Epoch 7/7\n",
            " - 789s - loss: 0.3742 - acc: 0.8591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f06c7038d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "akzRbu4N7AHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we train the Network. We should run much more than 7 epoch, But in practice its has to be trained for more iterations."
      ]
    },
    {
      "metadata": {
        "id": "CWx8cFcy7AH8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extracting a validation set, and measuring score and accuracy."
      ]
    },
    {
      "metadata": {
        "id": "XCmfXxc_7AH-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9e2ca6be-3754-468a-e8b6-b876b7a9b2a9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524477267488,
          "user_tz": -330,
          "elapsed": 33906,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "validation_size = 300\n",
        "\n",
        "X_validate = X_test[-validation_size:]\n",
        "Y_validate = Y_test[-validation_size:]\n",
        "X_test = X_test[:-validation_size]\n",
        "Y_test = Y_test[:-validation_size]\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 0.95\n",
            "acc: 0.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SHLDpDxK7AIE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally measuring the number of correct guesses. "
      ]
    },
    {
      "metadata": {
        "id": "D_EaUvhpM2ju",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CYuuEHsE7AIG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d73e105b-e7cb-4b1e-9393-d6b982189f10",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524477734108,
          "user_tz": -330,
          "elapsed": 464154,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pos_cnt, neg_cnt, pos_correct, neg_correct, neutral_correct,neutral_cnt  = 0, 0, 0, 0, 0, 0\n",
        "for x in range(len(X_validate)):\n",
        "    \n",
        "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
        "   \n",
        "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
        "        if np.argmax(Y_validate[x]) == 0:\n",
        "            neg_correct += 1\n",
        "        if np.argmax(Y_validate[x]) == 1:\n",
        "            neutral_correct += 1\n",
        "        else:\n",
        "            pos_correct += 1\n",
        "       \n",
        "    if np.argmax(Y_validate[x]) == 0:\n",
        "        neg_cnt += 1\n",
        "    elif np.argmax(Y_validate[x]) == 1:\n",
        "        neutral_cnt += 1\n",
        "    else:\n",
        "        pos_cnt += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
        "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")\n",
        "\n",
        "print(\"neutral_accuracy\", neutral_correct/neutral_cnt*100, \"%\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('pos_acc', 100, '%')\n",
            "('neg_acc', 0, '%')\n",
            "('neutral_accuracy', 0, '%')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BhyD57PL7AIO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, an example on predicting an arbitrary review sentiment:"
      ]
    },
    {
      "metadata": {
        "id": "jBLE6XIk7AIQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "ffe17cf7-ec64-40cd-e9de-0247798db692",
        "executionInfo": {
          "status": "error",
          "timestamp": 1524477735228,
          "user_tz": -330,
          "elapsed": 946,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "twt = 'Meetings: Because none of us is as dumb as all of us.'\n",
        "#vectorizing the review by the pre-fitted tokenizer instance\n",
        "twt = tokenizer.texts_to_sequences(twt)\n",
        "#padding the review to have exactly the same shape as `embedding_2` input\n",
        "twt = pad_sequences(twt, maxlen=28, dtype='int32', padding='post', truncating='post', value=0)\n",
        "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
        "if(np.argmax(sentiment) == 0):\n",
        "    print(\"negative\")\n",
        "\n",
        "elif (np.argmax(sentiment) == 2):\n",
        "    print(\"positive\")\n",
        "    \n",
        "else (np.argmax(sentiment) == 1):\n",
        "    print(\"neutral\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-f33688f882ea>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    else (np.argmax(sentiment) == 1):\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HQgQJRdj7AIW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}