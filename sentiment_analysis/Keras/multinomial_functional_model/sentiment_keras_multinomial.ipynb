{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_keras_with_aspect.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1NV77r4wgqT7YBIj6ngj0vXOXguZnJSTl",
          "timestamp": 1524360411042
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "eGGFM3vp7AGs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Sentiment Analysis:** the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral. \n"
      ]
    },
    {
      "metadata": {
        "id": "NKwryeAn7AGy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "xyWrujbd7AG0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeDIRX6Q7AHC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Only keeping the necessary columns."
      ]
    },
    {
      "metadata": {
        "id": "5jzvy4R57AHG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c537cda6-5710-417f-e253-bab3cfe8c05a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524461981750,
          "user_tz": -330,
          "elapsed": 1442,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://play.minio.io:9000/rao/data_1_train.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=Q3AM3UQ867SPQQA43P2F%2F20180422%2F%2Fs3%2Faws4_request&X-Amz-Date=20180422T014411Z&X-Amz-Expires=432000&X-Amz-SignedHeaders=host&X-Amz-Signature=30f103b98d02bf9a8271aa3347d2872d313cfb882a068a1f205ea0e6d1f50a69')\n",
        "# Keeping only the neccessary columns\n",
        "print (data.columns.tolist())\n",
        "\n",
        "data = data[[' text',' class']]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['example_id', ' text', ' aspect_term', ' term_location', ' class']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H97KzpuR7AHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "NWw_2yXA7AHU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fd7dd503-e2ad-4bb3-80b5-020011a39061",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524461983396,
          "user_tz": -330,
          "elapsed": 756,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#data = data[data.sentiment != \"Neutral\"]\n",
        "data[' text'] = data[' text'].apply(lambda x: x.lower())\n",
        "data[' text'] = data[' text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "print(data[ data[' class'] == 1].size)\n",
        "print(data[ data[' class'] == 0].size)\n",
        "print(data[ data[' class'] == -1].size)\n",
        "\n",
        "\n",
        "max_fatures = 1000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data[' text'].values)\n",
        "X = tokenizer.texts_to_sequences(data[' text'].values)\n",
        "X = pad_sequences(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1878\n",
            "872\n",
            "1656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GekL5Y7g7AHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, I compose the LSTM Network. Note that **embed_dim**, **lstm_out**, **batch_size**, **droupout_x** variables are hyperparameters, their values are somehow intuitive, can be and must be played with in order to achieve good results. Please also note that I am using softmax as activation function. The reason is that our Network is using categorical crossentropy, and softmax is just the right activation method for that."
      ]
    },
    {
      "metadata": {
        "id": "kmiIF-oF7AHi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "81bc36fd-7a29-4856-d6e6-e29d80d43f9c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524461984842,
          "user_tz": -330,
          "elapsed": 1336,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1785, 128)         128000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 1785, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 591       \n",
            "=================================================================\n",
            "Total params: 383,391\n",
            "Trainable params: 383,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4U3gK3rP7AHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hereby I declare the train and test dataset."
      ]
    },
    {
      "metadata": {
        "id": "1FTHSrn97AHq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "51d0beeb-7706-4795-ddb5-7a2e3c30af5c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524461986054,
          "user_tz": -330,
          "elapsed": 1112,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(data[' class']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((1476, 1785), (1476, 3))\n",
            "((727, 1785), (727, 3))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "akzRbu4N7AHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we train the Network. We should run much more than 7 epoch, But in practice its has to be trained for more iterations."
      ]
    },
    {
      "metadata": {
        "id": "LJewLDTr7AHy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b6d9131-b597-46c8-c8df-284f6c26285f"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CWx8cFcy7AH8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extracting a validation set, and measuring score and accuracy."
      ]
    },
    {
      "metadata": {
        "id": "XCmfXxc_7AH-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "5b95ec34-b4fe-4b19-b013-adfbd2962c9b",
        "executionInfo": {
          "status": "error",
          "timestamp": 1524364914618,
          "user_tz": -330,
          "elapsed": 6512,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "validation_size = 300\n",
        "\n",
        "X_validate = X_test[-validation_size:]\n",
        "Y_validate = Y_test[-validation_size:]\n",
        "X_test = X_test[:-validation_size]\n",
        "Y_test = Y_test[:-validation_size]\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-17b23d2cd986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalidation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_validate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mY_validate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SHLDpDxK7AIE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally measuring the number of correct guesses. "
      ]
    },
    {
      "metadata": {
        "id": "D_EaUvhpM2ju",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CYuuEHsE7AIG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "71ffe6b0-dad3-4484-ca7d-a8fbca20ce2d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524359947872,
          "user_tz": -330,
          "elapsed": 7282,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
        "for x in range(len(X_validate)):\n",
        "    \n",
        "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
        "   \n",
        "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
        "        if np.argmax(Y_validate[x]) == 0:\n",
        "            neg_correct += 1\n",
        "        if np.argmax(Y_validate[x]) == 1:\n",
        "            neutral_correct += 1\n",
        "        else:\n",
        "            pos_correct += 1\n",
        "       \n",
        "    if np.argmax(Y_validate[x]) == 0:\n",
        "        neg_cnt += 1\n",
        "    elif np.argmax(Y_validate[x]) == 1:\n",
        "        neutral_cnt += 1\n",
        "    else:\n",
        "        pos_cnt += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
        "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")\n",
        "\n",
        "print(\"neutral_accuracy\", neutral_correct/neutral_cnt*100, \"%\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_acc 53.398058252427184 %\n",
            "neg_acc 93.87069689336693 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BhyD57PL7AIO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, an example on predicting an arbitrary review sentiment:"
      ]
    },
    {
      "metadata": {
        "id": "jBLE6XIk7AIQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92b0575f-79c7-4463-d7db-70d67d923d1e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524359949150,
          "user_tz": -330,
          "elapsed": 1204,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "twt = 'Meetings: Because none of us is as dumb as all of us.'\n",
        "#vectorizing the review by the pre-fitted tokenizer instance\n",
        "twt = tokenizer.texts_to_sequences(twt)\n",
        "#padding the review to have exactly the same shape as `embedding_2` input\n",
        "twt = pad_sequences(twt, maxlen=28, dtype='int32', padding='post', truncating='post', value=0)\n",
        "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
        "if(np.argmax(sentiment) == 0):\n",
        "    print(\"negative\")\n",
        "\n",
        "elif (np.argmax(sentiment) == 2):\n",
        "    print(\"positive\")\n",
        "    \n",
        "else (np.argmax(sentiment) == 1):\n",
        "    print(\"neutral\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HQgQJRdj7AIW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}