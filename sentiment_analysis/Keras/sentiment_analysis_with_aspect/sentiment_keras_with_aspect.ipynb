{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_keras_with_aspect.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1XM9YLDjeCn7Wbs3tVc0PyM54hVTdTfh4",
          "timestamp": 1524473214486
        },
        {
          "file_id": "1tdUPLgbNVMvO5SPcc4XAfqHzOLhSoXb4",
          "timestamp": 1524466254418
        },
        {
          "file_id": "1NV77r4wgqT7YBIj6ngj0vXOXguZnJSTl",
          "timestamp": 1524360411042
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "eGGFM3vp7AGs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Sentiment Analysis:** the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral. \n"
      ]
    },
    {
      "metadata": {
        "id": "NKwryeAn7AGy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "xyWrujbd7AG0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense ,LSTM,concatenate,Input,Flatten\n",
        "import re\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeDIRX6Q7AHC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Only keeping the necessary columns."
      ]
    },
    {
      "metadata": {
        "id": "5jzvy4R57AHG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e7c04af-ede6-4b28-d800-7c40907d5617",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524497179598,
          "user_tz": -330,
          "elapsed": 818,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://play.minio.io:9000/rao/data_1_train.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=Q3AM3UQ867SPQQA43P2F%2F20180422%2F%2Fs3%2Faws4_request&X-Amz-Date=20180422T014411Z&X-Amz-Expires=432000&X-Amz-SignedHeaders=host&X-Amz-Signature=30f103b98d02bf9a8271aa3347d2872d313cfb882a068a1f205ea0e6d1f50a69')\n",
        "# Keeping only the neccessary columns\n",
        "print (data.columns.tolist())\n",
        "\n",
        "data = data[[' text',' class',' aspect_term']]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['example_id', ' text', ' aspect_term', ' term_location', ' class']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H97KzpuR7AHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "NWw_2yXA7AHU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "bb2f874b-8ce3-4a2a-db5d-23f5c29afdda",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524497182692,
          "user_tz": -330,
          "elapsed": 1454,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#data = data[data.sentiment != \"Neutral\"]\n",
        "data[' text'] = data[' text'].apply(lambda x: x.lower())\n",
        "data[' text'] = data[' text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "#print(data[' aspect_term'].unique())\n",
        "data[' aspect_term'] = data[' aspect_term'].apply(lambda x: x.lower())\n",
        "data[' aspect_term'] = data[' aspect_term'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
        "\n",
        "print(data[ data[' class'] == 1].size)\n",
        "print(data[ data[' class'] == 0].size)\n",
        "print(data[ data[' class'] == -1].size)\n",
        "\n",
        "\n",
        "max_fatures = 1000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data[' text'].values)\n",
        "X = tokenizer.texts_to_sequences(data[' text'].values)\n",
        "X = pad_sequences(X)\n",
        "print(X.shape)\n",
        "\n",
        "aspect_X = tokenizer.texts_to_sequences(data[' aspect_term'].values)\n",
        "\n",
        "aspect_X = pad_sequences(aspect_X)\n",
        "\n",
        "print(aspect_X.shape)\n",
        "print(aspect_X.shape[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2817\n",
            "1308\n",
            "2484\n",
            "(2203, 1785)\n",
            "(2203, 6)\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GekL5Y7g7AHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, I compose the LSTM Network. Note that **embed_dim**, **lstm_out**, **batch_size**, **droupout_x** variables are hyperparameters, their values are somehow intuitive, can be and must be played with in order to achieve good results. Please also note that I am using softmax as activation function. The reason is that our Network is using categorical crossentropy, and softmax is just the right activation method for that."
      ]
    },
    {
      "metadata": {
        "id": "kmiIF-oF7AHi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "1f3c3171-57ab-4da0-a15a-bb3d88df6525",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524497184288,
          "user_tz": -330,
          "elapsed": 1346,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "# The LSTM network which takes in the proceessed input using embedding layer.\n",
        "input_1 = Input(shape=(X.shape[1], ))\n",
        "word_embedding = Embedding(max_fatures, embed_dim,input_length = X.shape[1])(input_1)\n",
        "drop_out_1 = SpatialDropout1D(0.4)(word_embedding)\n",
        "lstm_1 = LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)(drop_out_1)\n",
        "\n",
        "output_1 = Dense(50,activation='relu')(lstm_1)\n",
        "\n",
        "# The ASpect term is fed through a neural network \n",
        "\n",
        "input_2 = Input(shape=(aspect_X.shape[1], ))\n",
        "word_embedding_2 = Embedding(max_fatures, embed_dim,input_length = X.shape[1])(input_2)\n",
        "#drop_out_2 = SpatialDropout1D(0.2)(word_embedding_2)\n",
        "lstm_2 = LSTM(lstm_out, dropout=0.0, recurrent_dropout=0.0)(word_embedding_2)\n",
        "\n",
        "output_2 = Dense(20,activation='relu')(lstm_2)\n",
        "\n",
        "merge = concatenate([output_1, output_2])\n",
        "# interpretation model\n",
        "hidden1 = Dense(25, activation='relu')(merge)\n",
        "hidden2 = Dense(10, activation='relu')(hidden1)\n",
        "output = Dense(3, activation='sigmoid')(hidden2)\n",
        "model = Model(inputs=[input_1, input_2], outputs=output)\n",
        "\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "    \n",
        "print(model.summary())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 1785)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 1785, 128)    128000      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_9 (SpatialDro (None, 1785, 128)    0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 1785, 128)    128000      input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   (None, 196)          254800      spatial_dropout1d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  (None, 196)          254800      embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 50)           9850        lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 20)           3940        lstm_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 70)           0           dense_20[0][0]                   \n",
            "                                                                 dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 25)           1775        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 10)           260         dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 3)            33          dense_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 781,458\n",
            "Trainable params: 781,458\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4U3gK3rP7AHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hereby I declare the train and test dataset."
      ]
    },
    {
      "metadata": {
        "id": "1FTHSrn97AHq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "113f9b63-70c8-42c8-cd24-d35d451e96f5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524497185446,
          "user_tz": -330,
          "elapsed": 1046,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(data[' class']).values\n",
        "X_train, X_test,  aspect_X_train, aspect_X_test, Y_train, Y_test = train_test_split(X, aspect_X, Y, test_size = 0.33, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "print(aspect_X_train.shape,aspect_X_test.shape)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((1476, 1785), (1476, 3))\n",
            "((727, 1785), (727, 3))\n",
            "((1476, 6), (727, 6))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LJewLDTr7AHy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "0ffcb4dd-a696-4e71-c953-9c06e81b8b61"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "model.fit([X_train, aspect_X_train], Y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            " - 308s - loss: 1.0704 - acc: 0.4153\n",
            "Epoch 2/7\n",
            " - 304s - loss: 1.0198 - acc: 0.4654\n",
            "Epoch 3/7\n",
            " - 304s - loss: 0.9749 - acc: 0.5603\n",
            "Epoch 4/7\n",
            " - 320s - loss: 0.9930 - acc: 0.4431\n",
            "Epoch 5/7\n",
            " - 318s - loss: 0.9164 - acc: 0.5576\n",
            "Epoch 6/7\n",
            " - 314s - loss: 0.7340 - acc: 0.6606\n",
            "Epoch 7/7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "akzRbu4N7AHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we train the Network. We should run much more than 7 epoch, But in practice its has to be trained for more iterations."
      ]
    },
    {
      "metadata": {
        "id": "CWx8cFcy7AH8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extracting a validation set, and measuring score and accuracy."
      ]
    },
    {
      "metadata": {
        "id": "XCmfXxc_7AH-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2a5e4f5-bbc9-440a-ec1f-c8c3aef2c96d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524465802030,
          "user_tz": -330,
          "elapsed": 34222,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "validation_size = 300\n",
        "\n",
        "X_validate = X_test[-validation_size:]\n",
        "Y_validate = Y_test[-validation_size:]\n",
        "X_test = X_test[:-validation_size]\n",
        "Y_test = Y_test[:-validation_size]\n",
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 1.01\n",
            "acc: 0.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SHLDpDxK7AIE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally measuring the number of correct guesses. "
      ]
    },
    {
      "metadata": {
        "id": "D_EaUvhpM2ju",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CYuuEHsE7AIG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pos_cnt, neg_cnt, pos_correct, neg_correct, neutral_correct,neutral_cnt  = 0, 0, 0, 0, 0, 0\n",
        "for x in range(len(X_validate)):\n",
        "    \n",
        "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
        "   \n",
        "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
        "        if np.argmax(Y_validate[x]) == 0:\n",
        "            neg_correct += 1\n",
        "        if np.argmax(Y_validate[x]) == 1:\n",
        "            neutral_correct += 1\n",
        "        else:\n",
        "            pos_correct += 1\n",
        "       \n",
        "    if np.argmax(Y_validate[x]) == 0:\n",
        "        neg_cnt += 1\n",
        "    elif np.argmax(Y_validate[x]) == 1:\n",
        "        neutral_cnt += 1\n",
        "    else:\n",
        "        pos_cnt += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
        "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")\n",
        "\n",
        "print(\"neutral_accuracy\", neutral_correct/neutral_cnt*100, \"%\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BhyD57PL7AIO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, an example on predicting an arbitrary review sentiment:"
      ]
    },
    {
      "metadata": {
        "id": "jBLE6XIk7AIQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92b0575f-79c7-4463-d7db-70d67d923d1e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524359949150,
          "user_tz": -330,
          "elapsed": 1204,
          "user": {
            "displayName": "karthic rao",
            "photoUrl": "//lh4.googleusercontent.com/-IjQPV2IT_dg/AAAAAAAAAAI/AAAAAAAAAKY/koCnnupHc0Y/s50-c-k-no/photo.jpg",
            "userId": "117034387844131328042"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "twt = 'Meetings: Because none of us is as dumb as all of us.'\n",
        "#vectorizing the review by the pre-fitted tokenizer instance\n",
        "twt = tokenizer.texts_to_sequences(twt)\n",
        "#padding the review to have exactly the same shape as `embedding_2` input\n",
        "twt = pad_sequences(twt, maxlen=28, dtype='int32', padding='post', truncating='post', value=0)\n",
        "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
        "if(np.argmax(sentiment) == 0):\n",
        "    print(\"negative\")\n",
        "\n",
        "elif (np.argmax(sentiment) == 2):\n",
        "    print(\"positive\")\n",
        "    \n",
        "else (np.argmax(sentiment) == 1):\n",
        "    print(\"neutral\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HQgQJRdj7AIW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}